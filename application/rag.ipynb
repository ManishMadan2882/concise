{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to RAG Applications\n",
    "\n",
    "This notebook creates a simple RAG (Retrieval-Augmented Generation) system to answer questions from a PDF document using an open-source model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_FILE = \"MANISHMADAN.pdf\"\n",
    "\n",
    "# We'll be using Llama 3.2 8B for this example.\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the PDF document\n",
    "\n",
    "Let's start by loading the PDF document and breaking it down into separate pages.\n",
    "\n",
    "<img src='images/documents.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 1\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_FILE)\n",
    "pages = loader.load()\n",
    "\n",
    "print(f\"Number of pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the pages in chunks\n",
    "\n",
    "Pages are too long, so let's split pages into different chunks.\n",
    "\n",
    "<img src='images/splitter.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 3\n",
      "Length of a chunk: 1487\n",
      "Content of a chunk: Frontend : React.js, Next.js, TailwindCSS, MaterialUI, ChakraUI, HTML, CSS\n",
      "Backend : Node.js, Express, Flask\n",
      "Database : MongoDB, PostgreSQL\n",
      "Tools : Git, GitHub, Docker, Postman\n",
      "Projects\n",
      "LegalEdge |Node.js, JavaScript, Express.js, MongoDb github.com/ManishMadan2882/hackman-team\n",
      "•Engineered a sophisticated server-side solution empowering legal advice seekers through a community platform, driving\n",
      "accessibility and collaboration in legal consultations.\n",
      "•Integrated an anonymous posting feature, to share confidential matters discreetly, enhancing user privacy and trust.\n",
      "algoRythm |React, Node.js, Express.js, Docker, TailwindCSS github.com/ManishMadan2882/algoRythm\n",
      "•Virtual Compiler for 5+ programming languages (C, C++, Java, JavaScript, Python, C#) hosted on Vercel .\n",
      "•Executed child processes to improve performance, enabling concurrent execution and efficient resource utilization.\n",
      "•Containerized and deployed the API with Docker, ensuring compatibility across multiple runtime environments.\n",
      "blog-app |React, Node.js, Express.js, MongoDB, MaterialUI github.com/ManishMadan2882/blog-app\n",
      "•Developed and deployed a feature-rich blog application using React.js, Node.js, and MongoDB on Render.\n",
      "•Integrated a sophisticated ReactQuill based Text Editor for drafting blogs, enhancing user engagement and interaction.\n",
      "Achievements\n",
      "Hackman V6 |2nd among 50 teams June 2023\n",
      "•Innovated a Prototype to enhance Client-lawyer communication and fostered community for legal help, within 24 hours.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=100)\n",
    "\n",
    "chunks = splitter.split_documents(pages)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"Length of a chunk: {len(chunks[1].page_content)}\")\n",
    "print(\"Content of a chunk:\", chunks[1].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the chunks in a vector store\n",
    "\n",
    "We can now generate embeddings for every chunk and store them in a vector store.\n",
    "\n",
    "<img src='images/vectorstore.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=MODEL)\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a retriever\n",
    "\n",
    "We can use a retriever to find chunks in the vector store that are similar to a supplied question.\n",
    "\n",
    "<img src='images/retriever.png' width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'MANISHMADAN.pdf', 'page': 0}, page_content='•Pioneered Calendly based appointment booking functionality to create an interface between Lawyers and potential Clients.\\nHack-elite |1st Runner up August 2023\\n•Implemented MindsDB for abstraction of ML Regression Models to trigger health risks with an accuracy of 76%.\\n•Integrated a Fitness Bot with OpenAI GPT 3.0 API, collecting information from Google Fit API for personalization.'),\n",
       " Document(metadata={'source': 'MANISHMADAN.pdf', 'page': 0}, page_content='Frontend : React.js, Next.js, TailwindCSS, MaterialUI, ChakraUI, HTML, CSS\\nBackend : Node.js, Express, Flask\\nDatabase : MongoDB, PostgreSQL\\nTools : Git, GitHub, Docker, Postman\\nProjects\\nLegalEdge |Node.js, JavaScript, Express.js, MongoDb github.com/ManishMadan2882/hackman-team\\n•Engineered a sophisticated server-side solution empowering legal advice seekers through a community platform, driving\\naccessibility and collaboration in legal consultations.\\n•Integrated an anonymous posting feature, to share confidential matters discreetly, enhancing user privacy and trust.\\nalgoRythm |React, Node.js, Express.js, Docker, TailwindCSS github.com/ManishMadan2882/algoRythm\\n•Virtual Compiler for 5+ programming languages (C, C++, Java, JavaScript, Python, C#) hosted on Vercel .\\n•Executed child processes to improve performance, enabling concurrent execution and efficient resource utilization.\\n•Containerized and deployed the API with Docker, ensuring compatibility across multiple runtime environments.\\nblog-app |React, Node.js, Express.js, MongoDB, MaterialUI github.com/ManishMadan2882/blog-app\\n•Developed and deployed a feature-rich blog application using React.js, Node.js, and MongoDB on Render.\\n•Integrated a sophisticated ReactQuill based Text Editor for drafting blogs, enhancing user engagement and interaction.\\nAchievements\\nHackman V6 |2nd among 50 teams June 2023\\n•Innovated a Prototype to enhance Client-lawyer communication and fostered community for legal help, within 24 hours.'),\n",
       " Document(metadata={'source': 'MANISHMADAN.pdf', 'page': 0}, page_content='Manish Madan\\n/githubgithub.com/ManishMadan2882 ♂phone+91 7307037556 /linkedinlinkedin.com/in/manishmadan2882 /envel⌢pemanishmadan321@gmail.com\\nEducation\\nDayananda Sagar College of Engineering, Bengaluru 2021-2025\\nBachelor of Engineering in Information Science Current GPA: 8.5/10\\nExperience\\nSoftware Engineer February 2024 - Present\\nArc53 LTD Edinburgh, United Kingdom (Remote)\\n•Published an NPM library for embedding an assistant chatbot widget, achieving a peak of 534 weekly downloads.\\n•Internationalized the application using React i18next, creating a robust structure for multilingual support.\\n•Identified and rectified 20+ software bugs, resulting in a seamless and intuitive interface reducing customer support issues.\\nFront-end Developer Intern November 2023 - January 2023\\nOptigrit Bengaluru, India\\n•Led the creation of interactive dashboards with Material UI, enabling real-time task management and progress tracking.\\n•Streamlined reporting processes and reduced manual data entry time by 40% for educational content management platform\\nFull-stack Developer Intern November 2023 - December 2023\\nWIN Research Centre Bengaluru, India\\n•Engineered a scalable database schema for MongoDB, created 15+ API endpoints for an e-commerce platform serving\\nwashing service providers; increased data retrieval speed by 40% and supported 50% more concurrent users\\nSkills\\nLanguages : Javascript, Typescript, Java, Python\\nFrontend : React.js, Next.js, TailwindCSS, MaterialUI, ChakraUI, HTML, CSS')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"What can you get away with when you only have a small number of users?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the model\n",
    "\n",
    "We'll be using Ollama to load the local model in memory. After creating the model, we can invoke it with a question to get the response back.\n",
    "\n",
    "<img src='images/model.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not aware of the current President of the United States, as my knowledge cutoff is December 2023. However, I can suggest some ways for you to find out who the current President is:\\n\\n1. Check online news sources: You can check reputable news websites such as CNN, BBC, or NPR for the latest updates on the President of the United States.\\n2. Visit the official White House website: The official White House website (whitehouse.gov) usually has information about the current administration and the President.\\n3. Look up government websites: You can also check the official website of the U.S. Government (usa.gov) or the Federal Register for information on the current President.\\n\\nPlease note that my knowledge may not be up-to-date, and I recommend verifying the information through multiple sources to ensure accuracy.\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-05T20:49:18.544040819Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 10849541808, 'load_duration': 17312120, 'prompt_eval_count': 34, 'prompt_eval_duration': 792166000, 'eval_count': 165, 'eval_duration': 9997184000}, id='run-f4eb438c-3dac-4907-a344-e363b5d617df-0', usage_metadata={'input_tokens': 34, 'output_tokens': 165, 'total_tokens': 199})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(model=MODEL, temperature=0)\n",
    "model.invoke(\"Who is the president of the United States?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the model's response\n",
    "\n",
    "The response from the model is an `AIMessage` instance containing the answer. We can extract the text answer by using the appropriate output parser. We can connect the model and the parser using a chain.\n",
    "\n",
    "<img src='images/parser.png' width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk is a South African-born entrepreneur, inventor, and business magnate. He is one of the most successful and influential figures in the tech industry today.\n",
      "\n",
      "Early Life and Education:\n",
      "\n",
      "Musk was born on June 28, 1971, in Pretoria, South Africa. He developed an interest in computing and programming at an early age and taught himself computer programming. He moved to Canada in 1992 to attend college, and later transferred to the University of Pennsylvania, where he graduated with a degree in economics and physics.\n",
      "\n",
      "Career:\n",
      "\n",
      "Musk's career can be divided into several stages:\n",
      "\n",
      "1. Early years: Musk worked as a software engineer at various companies, including Pinnacle Research and X.com (which later became PayPal).\n",
      "2. PayPal: In 2000, Musk co-founded PayPal, an online payment system that was acquired by eBay for $1.5 billion in 2002.\n",
      "3. SpaceX: In 2002, Musk founded SpaceX, a private aerospace manufacturer and space transport services company with the goal of reducing space transportation costs and enabling the colonization of Mars.\n",
      "4. Tesla: In 2004, Musk co-founded Tesla, Inc., an electric vehicle and clean energy company that has become one of the leading players in the EV market.\n",
      "5. Neuralink: In 2016, Musk founded Neuralink, a neurotechnology company developing brain-machine interfaces (BMIs) to enhance human cognition and potentially treat medical conditions such as paralysis and depression.\n",
      "6. The Boring Company: In 2016, Musk also founded The Boring Company, which aims to reduce traffic congestion by building underground tunnels for high-speed transportation.\n",
      "\n",
      "Achievements:\n",
      "\n",
      "Musk has achieved numerous milestones in his career, including:\n",
      "\n",
      "* Becoming the CEO of SpaceX at age 31, making him one of the youngest CEOs in the industry.\n",
      "* Leading Tesla to become one of the leading electric vehicle manufacturers in the world.\n",
      "* Developing reusable rockets that have significantly reduced the cost of access to space.\n",
      "* Being named one of the most influential people in the world by TIME magazine.\n",
      "\n",
      "Controversies:\n",
      "\n",
      "Musk has also been involved in several controversies, including:\n",
      "\n",
      "* Twitter feuds with other celebrities and politicians\n",
      "* Accusations of making false claims about his companies' progress and achievements\n",
      "* Concerns over his leadership style and work ethic\n",
      "* Criticisms of his environmental policies and the impact of Tesla's production on the environment\n",
      "\n",
      "Personal Life:\n",
      "\n",
      "Musk has been married three times and has seven children. He is known for his demanding work schedule and has stated that he works over 100 hours per week.\n",
      "\n",
      "Overall, Elon Musk is a highly influential and successful entrepreneur who has made significant contributions to the tech industry and beyond.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "print(chain.invoke(\"Who is elon musk?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a prompt\n",
    "\n",
    "In addition to the question we want to ask, we also want to provide the model with the context from the PDF file. We can use a prompt template to define and reuse the prompt we'll use with the model.\n",
    "\n",
    "\n",
    "<img src='images/prompt.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an assistant that provides answers to questions based on\n",
      "a given context. \n",
      "\n",
      "Answer the question based on the context. If you can't answer the\n",
      "question, reply \"I don't know\".\n",
      "\n",
      "Be as concise as possible and go straight to the point.\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an assistant that provides answers to questions based on\n",
    "a given context. \n",
    "\n",
    "Answer the question based on the context. If you can't answer the\n",
    "question, reply \"I don't know\".\n",
    "\n",
    "Be as concise as possible and go straight to the point.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the prompt to the chain\n",
    "\n",
    "We can now chain the prompt with the model and the parser.\n",
    "\n",
    "<img src='images/chain1.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anna.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\n",
    "    \"context\": \"Anna's sister is Susan\", \n",
    "    \"question\": \"Who is Susan's sister?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the retriever to the chain\n",
    "\n",
    "Finally, we can connect the retriever to the chain to get the context from the vector store.\n",
    "\n",
    "<img src='images/chain2.png' width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the chain to answer questions\n",
    "\n",
    "Finally, we can use the chain to ask questions that will be answered using the PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What can you get away with when you only have a small number of users?\n",
      "Answer: With a small number of users, you can often get away with less robust or simplified features and infrastructure. In the context of Manish Madan's projects, this might mean:\n",
      "\n",
      "* Using a simpler database schema (as seen in the WIN Research Centre project)\n",
      "* Reducing the number of API endpoints (as seen in the WIN Research Centre project)\n",
      "* Streamlining reporting processes to reduce manual data entry time\n",
      "* Using less complex frontend frameworks or libraries (although Manish Madan's projects show he uses more advanced ones like React.js and Next.js)\n",
      "*************************\n",
      "\n",
      "Question: What's the most common unscalable thing founders have to do at the start?\n",
      "Answer: I don't know.\n",
      "*************************\n",
      "\n",
      "Question: What's one of the biggest things inexperienced founders and investors get wrong about startups?\n",
      "Answer: I don't know.\n",
      "*************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"What can you get away with when you only have a small number of users?\",\n",
    "    \"What's the most common unscalable thing founders have to do at the start?\",\n",
    "    \"What's one of the biggest things inexperienced founders and investors get wrong about startups?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer: {chain.invoke({'question': question})}\")\n",
    "    print(\"*************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
